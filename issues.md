# üöÄ Roadmap de proyecto de Meta-Learning

## 1Ô∏è‚É£ Preparaci√≥n y recopilaci√≥n de datos

**Objetivo:** Tener todos los datasets, resultados previos y meta-features listos para construir tu meta-dataset.

| Issue                       | Descripci√≥n                                                                                            | Prioridad | Notas                                                                   |
| --------------------------- | ------------------------------------------------------------------------------------------------------ | --------- | ----------------------------------------------------------------------- |
| `data-collection`           | Descargar datasets de OpenML relevantes para clasificaci√≥n y regresi√≥n.                                | Alta      | Usar OpenML100 como punto de partida. Guardar IDs de datasets y tareas. |
| `pipelines-historicos`      | Recopilar pipelines existentes de PIPES (o AutoML: TPOT, AlphaD3M) para cada dataset.                  | Alta      | Guardar como JSON o CSV, con hiperpar√°metros y resultados.              |
| `meta-feature-extraction`   | Extraer meta-features de cada dataset (num. instancias, num. atributos, stats por columna, etc.).      | Alta      | Implementar funciones reutilizables para meta-learning.                 |
| `meta-dataset-construction` | Construir meta-dataset combinando: meta-features, algoritmo, hiperpar√°metros, m√©tricas de performance. | Alta      | Formato: cada fila = configuraci√≥n + dataset + resultado.               |

---

## 2Ô∏è‚É£ An√°lisis exploratorio

**Objetivo:** Conocer la distribuci√≥n de algoritmos, hiperpar√°metros y m√©tricas.

| Issue                          | Descripci√≥n                                                          | Prioridad | Notas                                                     |
| ------------------------------ | -------------------------------------------------------------------- | --------- | --------------------------------------------------------- |
| `eda-algorithm-performance`    | Analizar qu√© algoritmos funcionan mejor seg√∫n tipo de dataset.       | Media     | Graficar rankings por precisi√≥n, tiempo y otras m√©tricas. |
| `eda-hyperparameter-impact`    | Evaluar tunabilidad de hiperpar√°metros.                              | Media     | Inspirarse en Probst et al. (Tunability).                 |
| `eda-meta-feature-correlation` | Estudiar correlaci√≥n de meta-features con performance de algoritmos. | Media     | √ötil para seleccionar meta-features m√°s predictivas.      |

---

## 3Ô∏è‚É£ Modelado de meta-learning

**Objetivo:** Entrenar modelos que recomienden algoritmos/pipelines para nuevas tareas.

| Issue                    | Descripci√≥n                                                                                               | Prioridad | Notas                                                          |
| ------------------------ | --------------------------------------------------------------------------------------------------------- | --------- | -------------------------------------------------------------- |
| `meta-learner-algorithm` | Implementar modelo que prediga ranking de algoritmos basado en meta-features.                             | Alta      | Puede ser k-NN, Random Forest o LightGBM.                      |
| `meta-learner-pipeline`  | Extender para predecir pipelines completos (selecci√≥n de preprocesamiento + algoritmo + hiperpar√°metros). | Alta      | Inspirarse en AlphaD3M y PIPES.                                |
| `loss-time-curve`        | Implementar evaluaci√≥n tipo *Loss-Time Curve* para ranking de recomendaciones.                            | Media     | Inspirado en ‚ÄúFast Algorithm Selection using Learning Curves‚Äù. |
| `pairwise-meta-rules`    | Opcional: mejorar ranking usando reglas pairwise sobre datasets similares.                                | Media     | Inspirado en *Pairwise meta-rules for better meta-learning*.   |

---

## 4Ô∏è‚É£ Evaluaci√≥n y validaci√≥n

**Objetivo:** Comprobar que el meta-learner genera recomendaciones √∫tiles.

| Issue                          | Descripci√≥n                                                                | Prioridad | Notas                                               |
| ------------------------------ | -------------------------------------------------------------------------- | --------- | --------------------------------------------------- |
| `cross-validation-meta`        | Validar meta-modelo usando *leave-one-dataset-out*.                        | Alta      | Cada dataset nuevo es tratado como una nueva tarea. |
| `compare-baseline`             | Comparar recomendaciones con valores por defecto y ranking aleatorio.      | Alta      | Medir mejora en performance y tiempo.               |
| `hyperparameter-tuning-effect` | Evaluar cu√°nto mejora la recomendaci√≥n ajustando hiperpar√°metros cr√≠ticos. | Media     | Basarse en an√°lisis de tunabilidad.                 |

---

## 5Ô∏è‚É£ Interfaz / Output

**Objetivo:** Facilitar uso de recomendaciones en nuevos datasets.

| Issue                | Descripci√≥n                                                                        | Prioridad | Notas                                                              |
| -------------------- | ---------------------------------------------------------------------------------- | --------- | ------------------------------------------------------------------ |
| `recommendation-api` | Implementar funci√≥n que reciba dataset y devuelva ranking de algoritmos/pipelines. | Alta      | Input: meta-features; Output: ranking + configuraciones sugeridas. |
| `visualizations`     | Graficar rankings, curvas de Loss-Time, impacto de hiperpar√°metros.                | Media     | √ötil para an√°lisis y reportes.                                     |
| `export-results`     | Guardar recomendaciones y evaluaciones en CSV/JSON para reproducibilidad.          | Media     | Integrar con pipelines hist√≥ricos.                                 |

---

## 6Ô∏è‚É£ Extras / Futuro

| Issue                             | Descripci√≥n                                                       | Prioridad | Notas                                   |
| --------------------------------- | ----------------------------------------------------------------- | --------- | --------------------------------------- |
| `integration-pipes`               | Integrar PIPES meta-dataset completo como referencia.             | Baja      | Para enriquecer hist√≥rico de pipelines. |
| `reinforcement-learning-pipeline` | Explorar MCTS o RL para optimizar pipelines autom√°ticamente.      | Baja      | Inspirado en AlphaD3M.                  |
| `hyperparameter-prioritization`   | Usar tunabilidad para priorizar tuning en pipelines recomendados. | Media     | Reduce tiempo de computaci√≥n.           |

---

```json
flowchart TD
    A[üì• Datasets OpenML / PIPES] --> B[üîπ Extracci√≥n de Meta-features]
    B --> C[üìä Construcci√≥n de Meta-dataset]
    C --> D[üîç An√°lisis Exploratorio]
    D --> E[ü§ñ Modelado de Meta-Learner]
    E --> F[üìà Evaluaci√≥n y Validaci√≥n]
    F --> G[üí° Recomendaciones de Algoritmos / Pipelines]
    G --> H[üìä Visualizaci√≥n y Exportaci√≥n de Resultados]

    subgraph "Preparaci√≥n de datos"
        A --> B
        B --> C
    end

    subgraph "An√°lisis y Modelado"
        C --> D
        D --> E
    end

    subgraph "Producci√≥n y Resultados"
        E --> F
        F --> G
        G --> H
    end

    %% Notas adicionales
    B -.-> B1[Incluye stats, n√∫mero de instancias, clases, correlaciones, etc.]
    E -.-> E1[Algoritmos: k-NN, Random Forest, LightGBM, RL para pipelines]
    F -.-> F1[Cross-validation, comparaci√≥n con baseline y valores por defecto]
    G -.-> G1[Ranking, hiperpar√°metros sugeridos, configuraci√≥n completa del pipeline]
```