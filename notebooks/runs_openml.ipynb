{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45fac321",
   "metadata": {},
   "source": [
    "# **RUN**\n",
    "\n",
    "Un run es:\n",
    "\n",
    "- un algoritmo (flow)\n",
    "\n",
    "- con hiperparámetros\n",
    "\n",
    "- entrenado y evaluado en una task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0b7555f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'area_under_roc_curve': 0.9944666666666667, 'average_cost': 0.0, 'f_measure': 0.9533286661999534, 'kappa': 0.93, 'kb_relative_information_score': 0.9289119924022927, 'mean_absolute_error': 0.03688888888888889, 'mean_prior_absolute_error': 0.44444444444444337, 'weighted_recall': 0.9533333333333334, 'number_of_instances': 150.0, 'precision': 0.9534480458850206, 'predictive_accuracy': 0.9533333333333333, 'prior_entropy': 1.5849625007211599, 'relative_absolute_error': 0.0830000000000002, 'root_mean_prior_squared_error': 0.4714045207910311, 'root_mean_squared_error': 0.14721714875954123, 'root_relative_squared_error': 0.3122947325844614, 'total_cost': 0.0, 'unweighted_recall': 0.9533333333333333}\n"
     ]
    }
   ],
   "source": [
    "import openml\n",
    "import pandas as pd\n",
    "from openml.tasks import TaskType\n",
    "\n",
    "run = openml.runs.get_run(10595819)\n",
    "print(run.evaluations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5f36b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_algorithm_ranking_for_dataset(dataset_id, metric=\"predictive_accuracy\"):\n",
    "\n",
    "    tasks = openml.tasks.list_tasks(\n",
    "        data_id=dataset_id,\n",
    "        task_type=TaskType.SUPERVISED_CLASSIFICATION,\n",
    "        output_format=\"dataframe\"\n",
    "    )\n",
    "    if tasks.empty:\n",
    "        return None\n",
    "\n",
    "    runs = openml.runs.list_runs(\n",
    "        task=tasks.index.tolist(),\n",
    "        output_format=\"dataframe\"\n",
    "    )\n",
    "    if runs.empty:\n",
    "        return None\n",
    "\n",
    "    rows = []\n",
    "\n",
    "    for run_id, row in runs.iterrows():\n",
    "        try:\n",
    "            run = openml.runs.get_run(run_id)\n",
    "            score = run.evaluations.get(metric)\n",
    "            if score is None:\n",
    "                continue\n",
    "            rows.append({\n",
    "                \"algorithm\": row[\"flow_name\"],\n",
    "                \"score\": score\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "    if not rows:\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    agg = df.groupby(\"algorithm\")[\"score\"].max().reset_index()\n",
    "\n",
    "    ranking = agg.sort_values(\"score\", ascending=False).reset_index(drop=True)\n",
    "    ranking[\"rank\"] = ranking.index + 1\n",
    "    ranking[\"metric\"] = metric\n",
    "\n",
    "    return ranking\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b73fa82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay runs con métricas válidas\n"
     ]
    }
   ],
   "source": [
    "ranking = get_algorithm_ranking_for_dataset(1)\n",
    "\n",
    "if ranking is None:\n",
    "    print(\"No hay runs con métricas válidas\")\n",
    "else:\n",
    "    print(ranking.head())\n",
    "\n",
    "\n",
    "# dataset_id   nombre\n",
    "# -----------  -------------------------\n",
    "# 3            kr-vs-kp\n",
    "# 6            letter\n",
    "# 11           balance-scale\n",
    "# 12           mfeat-factors\n",
    "# 15           breast-w\n",
    "# 31           credit-g\n",
    "# 37           diabetes\n",
    "# 44           spambase\n",
    "# 50           tic-tac-toe\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
