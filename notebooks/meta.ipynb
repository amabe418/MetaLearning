{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a808407",
   "metadata": {},
   "source": [
    "# Meta_Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e37f4340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openml\n",
    "from amltk.metalearning import compute_metafeatures\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a10d6e9",
   "metadata": {},
   "source": [
    "Los metafeatures que aparecen en openml."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4ade6b31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not download file from https://openml.org/datasets/0000/0031/dataset_31.pq: HTTPSConnectionPool(host='www.openml.org', port=443): Max retries exceeded with url: https://www.openml.org/datasets/0000/0031/dataset_31.pq (Caused by ResponseError('too many redirects'))\n",
      "Failed to download parquet, fallback on ARFF.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "La cantidad de metafeures calculadas es: 30\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "instance_count                                           1000.000000\n",
       "log_instance_count                                          6.907755\n",
       "number_of_classes                                           2.000000\n",
       "number_of_features                                         20.000000\n",
       "log_number_of_features                                      2.995732\n",
       "percentage_missing_values                                   0.000000\n",
       "percentage_of_instances_with_missing_values                 0.000000\n",
       "percentage_of_features_with_missing_values                  0.000000\n",
       "percentage_of_categorical_columns_with_missing_values       0.000000\n",
       "percentage_of_categorical_values_with_missing_values        0.000000\n",
       "percentage_of_numeric_columns_with_missing_values           0.000000\n",
       "percentage_of_numeric_values_with_missing_values            0.000000\n",
       "number_of_numeric_features                                  7.000000\n",
       "number_of_categorical_features                             13.000000\n",
       "ratio_numerical_features                                    0.350000\n",
       "ratio_categorical_features                                  0.650000\n",
       "ratio_features_to_instances                                 0.020000\n",
       "minority_class_imbalance                                    0.200000\n",
       "majority_class_imbalance                                    0.200000\n",
       "class_imbalance                                             0.400000\n",
       "mean_categorical_imbalance                                  0.500500\n",
       "std_categorical_imbalance                                   0.234994\n",
       "skewness_mean                                               0.920379\n",
       "skewness_std                                                0.904952\n",
       "skewness_min                                               -0.531348\n",
       "skewness_max                                                1.949628\n",
       "kurtosis_mean                                               0.924278\n",
       "kurtosis_std                                                1.785467\n",
       "kurtosis_min                                               -1.381449\n",
       "kurtosis_max                                                4.292590\n",
       "dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# descarga un dataset de OpenML con ID 31.\n",
    "\n",
    "dataset = openml.datasets.get_dataset(\n",
    "    31,  # id del dataset\n",
    "    download_data=True, # descarga los datos del dataset\n",
    "    download_features_meta_data=False, # no descarga información extra sobre las características.\n",
    "    download_qualities=False, # no descarga estadísticas de calidad del dataset\n",
    ")\n",
    "\n",
    "# obtiene los datos reales del dataset.\n",
    "X, y, _, _ = dataset.get_data(\n",
    "    dataset_format=\"dataframe\", # convierte los datos en un dataframe pandas\n",
    "    target=dataset.default_target_attribute, # selecciona la columna objetivo del dataset\n",
    ")\n",
    "\n",
    "# funcion que calcula metafeatures para un dataset.\n",
    "mfs = compute_metafeatures(X, y)\n",
    "\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"La cantidad de metafeures calculadas es: {len(mfs)}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "mfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9804b120",
   "metadata": {},
   "source": [
    "Podemos personalizar los meta-features propios usando esta sintaxis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6df745d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "La cantidad de metafeures calculadas es: 1\n",
      "----------------------------------------------------\n",
      "total_values    20000\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from amltk.metalearning import MetaFeature\n",
    "\n",
    "# crear una meta-features personalizada\n",
    "class TotalValues(MetaFeature):\n",
    "\n",
    "    @classmethod\n",
    "    def compute(\n",
    "        cls,\n",
    "        x: pd.DataFrame, # features del dataset(filas,columnas)\n",
    "        y: pd.Series | pd.DataFrame, # variable objetivo del dataset\n",
    "        dependancy_values: dict,\n",
    "    ) -> int:\n",
    "        return int(x.shape[0] * x.shape[1])\n",
    "\n",
    "mfs = compute_metafeatures(X, y, features=[TotalValues])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"La cantidad de metafeures calculadas es: {len(mfs)}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "print(mfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad10b2bf",
   "metadata": {},
   "source": [
    "Puedes usar `DatasetStatistic`, lo que estás creando es una estadística intermedia del dataset, no una metacaracterística final. OpenML la calcula una sola vez por llamada a `compute_features()`.\n",
    "\n",
    "Luego, cualquier metacaracterística (MetaFeature) que tenga esa estadística como dependencia puede usarla directamente desde el diccionario `dependancy_values`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "335705e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------\n",
      "La cantidad de metafeures calculadas es: 1\n",
      "----------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "percentage_n_a    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from amltk.metalearning import DatasetStatistic\n",
    "\n",
    "class NAValues(DatasetStatistic):\n",
    "    \"\"\"A mask of all NA values in a dataset\"\"\"\n",
    "\n",
    "    @classmethod\n",
    "    def compute(\n",
    "        cls,\n",
    "        x: pd.DataFrame,\n",
    "        y: pd.Series | pd.DataFrame,\n",
    "        dependancy_values: dict,\n",
    "    ) -> pd.DataFrame:\n",
    "        return x.isna()\n",
    "    \n",
    "\n",
    "class PercentageNA(MetaFeature):\n",
    "    \"\"\"The percentage of values missing\"\"\"\n",
    "\n",
    "    dependencies = (NAValues,)\n",
    "\n",
    "    @classmethod\n",
    "    def compute(\n",
    "        cls,\n",
    "        x: pd.DataFrame,\n",
    "        y: pd.Series | pd.DataFrame,\n",
    "        dependancy_values: dict,\n",
    "    ) -> int:\n",
    "        na_values = dependancy_values[NAValues]\n",
    "        n_na = na_values.sum().sum()\n",
    "        n_values = int(x.shape[0] * x.shape[1])\n",
    "        return float(n_na / n_values)\n",
    "\n",
    "mfs = compute_metafeatures(X, y, features=[PercentageNA])\n",
    "print(\"----------------------------------------------------\")\n",
    "print(f\"La cantidad de metafeures calculadas es: {len(mfs)}\")\n",
    "print(\"----------------------------------------------------\")\n",
    "mfs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464c547b",
   "metadata": {},
   "source": [
    "Para ver la descripción de una metacaracterística específica, puedes llamar a .description() sobre ella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a56a7426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "instance_count\n",
      "---\n",
      " * Number of instances in the dataset.\n",
      "---\n",
      "log_instance_count\n",
      "---\n",
      " * Logarithm of the number of instances in the dataset.\n",
      "---\n",
      "number_of_classes\n",
      "---\n",
      " * Number of classes in the dataset.\n",
      "---\n",
      "number_of_features\n",
      "---\n",
      " * Number of features in the dataset.\n",
      "---\n",
      "log_number_of_features\n",
      "---\n",
      " * Logarithm of the number of features in the dataset.\n",
      "---\n",
      "percentage_missing_values\n",
      "---\n",
      " * Percentage of missing values in the dataset.\n",
      "---\n",
      "percentage_of_instances_with_missing_values\n",
      "---\n",
      " * Percentage of instances with missing values.\n",
      "---\n",
      "percentage_of_features_with_missing_values\n",
      "---\n",
      " * Percentage of features with missing values.\n",
      "---\n",
      "percentage_of_categorical_columns_with_missing_values\n",
      "---\n",
      " * Percentage of categorical columns with missing values.\n",
      "---\n",
      "percentage_of_categorical_values_with_missing_values\n",
      "---\n",
      " * Percentage of categorical values with missing values.\n",
      "---\n",
      "percentage_of_numeric_columns_with_missing_values\n",
      "---\n",
      " * Percentage of numeric columns with missing values.\n",
      "---\n",
      "percentage_of_numeric_values_with_missing_values\n",
      "---\n",
      " * Percentage of numeric values with missing values.\n",
      "---\n",
      "number_of_numeric_features\n",
      "---\n",
      " * Number of numeric features in the dataset.\n",
      "---\n",
      "number_of_categorical_features\n",
      "---\n",
      " * Number of categorical features in the dataset.\n",
      "---\n",
      "ratio_numerical_features\n",
      "---\n",
      " * Ratio of numerical features to total features in the dataset.\n",
      "---\n",
      "ratio_categorical_features\n",
      "---\n",
      " * Ratio of categoricals features to total features in the dataset.\n",
      "---\n",
      "ratio_features_to_instances\n",
      "---\n",
      " * Ratio of features to instances in the dataset.\n",
      "---\n",
      "minority_class_imbalance\n",
      "---\n",
      " * Imbalance of the minority class in the dataset. 0 => Balanced. 1 imbalanced.\n",
      "---\n",
      "majority_class_imbalance\n",
      "---\n",
      " * Imbalance of the majority class in the dataset. 0 => Balanced. 1 imbalanced.\n",
      "---\n",
      "class_imbalance\n",
      "---\n",
      " * Mean Target Imbalance of the classes in general.\n",
      "\n",
      "    0 => Balanced. 1 Imbalanced.\n",
      "    \n",
      "---\n",
      "mean_categorical_imbalance\n",
      "---\n",
      " * The mean imbalance of categorical features.\n",
      "---\n",
      "std_categorical_imbalance\n",
      "---\n",
      " * The std imbalance of categorical features.\n",
      "---\n",
      "skewness_mean\n",
      "---\n",
      " * The mean skewness of numerical features.\n",
      "---\n",
      "skewness_std\n",
      "---\n",
      " * The std skewness of numerical features.\n",
      "---\n",
      "skewness_min\n",
      "---\n",
      " * The min skewness of numerical features.\n",
      "---\n",
      "skewness_max\n",
      "---\n",
      " * The max skewness of numerical features.\n",
      "---\n",
      "kurtosis_mean\n",
      "---\n",
      " * The mean kurtosis of numerical features.\n",
      "---\n",
      "kurtosis_std\n",
      "---\n",
      " * The std kurtosis of numerical features.\n",
      "---\n",
      "kurtosis_min\n",
      "---\n",
      " * The min kurtosis of numerical features.\n",
      "---\n",
      "kurtosis_max\n",
      "---\n",
      " * The max kurtosis of numerical features.\n",
      "---\n",
      "total_values\n",
      "---\n",
      " * \n",
      "---\n",
      "percentage_n_a\n",
      "---\n",
      " * The percentage of values missing\n"
     ]
    }
   ],
   "source": [
    "from amltk.metalearning import metafeature_descriptions\n",
    "\n",
    "descriptions = metafeature_descriptions()  # Obtiene un diccionario con todas las metacaracterísticas y sus descripciones\n",
    "for name, description in descriptions.items():  # Itera sobre todas\n",
    "    print(\"---\")\n",
    "    print(name)  # Imprime el nombre de la metacaracterística\n",
    "    print(\"---\")\n",
    "    print(\" * \" + description)  # Imprime su descripción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9702d2a4",
   "metadata": {},
   "source": [
    "# Dataset Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "322d1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not download file from https://openml.org/datasets/0000/0031/dataset_31.pq: HTTPSConnectionPool(host='www.openml.org', port=443): Max retries exceeded with url: https://www.openml.org/datasets/0000/0031/dataset_31.pq (Caused by ResponseError('too many redirects'))\n",
      "Failed to download parquet, fallback on ARFF.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset_31</th>\n",
       "      <th>dataset_3</th>\n",
       "      <th>dataset_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>instance_count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>3196.000000</td>\n",
       "      <td>57.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_instance_count</th>\n",
       "      <td>6.907755</td>\n",
       "      <td>8.069655</td>\n",
       "      <td>4.043051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_classes</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_features</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>log_number_of_features</th>\n",
       "      <td>2.995732</td>\n",
       "      <td>3.583519</td>\n",
       "      <td>2.772589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_instances_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_features_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_categorical_columns_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_categorical_values_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.410088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_numeric_columns_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_of_numeric_values_with_missing_values</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.304825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_numeric_features</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_categorical_features</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>8.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_numerical_features</th>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_categorical_features</th>\n",
       "      <td>0.650000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ratio_features_to_instances</th>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.011264</td>\n",
       "      <td>0.280702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>minority_class_imbalance</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.149123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>majority_class_imbalance</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.022215</td>\n",
       "      <td>0.149123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class_imbalance</th>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.044431</td>\n",
       "      <td>0.298246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean_categorical_imbalance</th>\n",
       "      <td>0.500500</td>\n",
       "      <td>0.632105</td>\n",
       "      <td>0.308063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std_categorical_imbalance</th>\n",
       "      <td>0.234994</td>\n",
       "      <td>0.286572</td>\n",
       "      <td>0.228906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness_mean</th>\n",
       "      <td>0.920379</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.255076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness_std</th>\n",
       "      <td>0.904952</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.420729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness_min</th>\n",
       "      <td>-0.531348</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.007217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>skewness_max</th>\n",
       "      <td>1.949628</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.318064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis_mean</th>\n",
       "      <td>0.924278</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.046258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis_std</th>\n",
       "      <td>1.785467</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.890029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis_min</th>\n",
       "      <td>-1.381449</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.035406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kurtosis_max</th>\n",
       "      <td>4.292590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.193069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total_values</th>\n",
       "      <td>20000.000000</td>\n",
       "      <td>115056.000000</td>\n",
       "      <td>912.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>percentage_n_a</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.357456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      dataset_31  \\\n",
       "instance_count                                       1000.000000   \n",
       "log_instance_count                                      6.907755   \n",
       "number_of_classes                                       2.000000   \n",
       "number_of_features                                     20.000000   \n",
       "log_number_of_features                                  2.995732   \n",
       "percentage_missing_values                               0.000000   \n",
       "percentage_of_instances_with_missing_values             0.000000   \n",
       "percentage_of_features_with_missing_values              0.000000   \n",
       "percentage_of_categorical_columns_with_missing_...      0.000000   \n",
       "percentage_of_categorical_values_with_missing_v...      0.000000   \n",
       "percentage_of_numeric_columns_with_missing_values       0.000000   \n",
       "percentage_of_numeric_values_with_missing_values        0.000000   \n",
       "number_of_numeric_features                              7.000000   \n",
       "number_of_categorical_features                         13.000000   \n",
       "ratio_numerical_features                                0.350000   \n",
       "ratio_categorical_features                              0.650000   \n",
       "ratio_features_to_instances                             0.020000   \n",
       "minority_class_imbalance                                0.200000   \n",
       "majority_class_imbalance                                0.200000   \n",
       "class_imbalance                                         0.400000   \n",
       "mean_categorical_imbalance                              0.500500   \n",
       "std_categorical_imbalance                               0.234994   \n",
       "skewness_mean                                           0.920379   \n",
       "skewness_std                                            0.904952   \n",
       "skewness_min                                           -0.531348   \n",
       "skewness_max                                            1.949628   \n",
       "kurtosis_mean                                           0.924278   \n",
       "kurtosis_std                                            1.785467   \n",
       "kurtosis_min                                           -1.381449   \n",
       "kurtosis_max                                            4.292590   \n",
       "total_values                                        20000.000000   \n",
       "percentage_n_a                                          0.000000   \n",
       "\n",
       "                                                        dataset_3   dataset_4  \n",
       "instance_count                                        3196.000000   57.000000  \n",
       "log_instance_count                                       8.069655    4.043051  \n",
       "number_of_classes                                        2.000000    2.000000  \n",
       "number_of_features                                      36.000000   16.000000  \n",
       "log_number_of_features                                   3.583519    2.772589  \n",
       "percentage_missing_values                                0.000000    0.357456  \n",
       "percentage_of_instances_with_missing_values              0.000000    0.982456  \n",
       "percentage_of_features_with_missing_values               0.000000    1.000000  \n",
       "percentage_of_categorical_columns_with_missing_...       0.000000    1.000000  \n",
       "percentage_of_categorical_values_with_missing_v...       0.000000    0.410088  \n",
       "percentage_of_numeric_columns_with_missing_values        0.000000    1.000000  \n",
       "percentage_of_numeric_values_with_missing_values         0.000000    0.304825  \n",
       "number_of_numeric_features                               0.000000    8.000000  \n",
       "number_of_categorical_features                          36.000000    8.000000  \n",
       "ratio_numerical_features                                 0.000000    0.500000  \n",
       "ratio_categorical_features                               1.000000    0.500000  \n",
       "ratio_features_to_instances                              0.011264    0.280702  \n",
       "minority_class_imbalance                                 0.022215    0.149123  \n",
       "majority_class_imbalance                                 0.022215    0.149123  \n",
       "class_imbalance                                          0.044431    0.298246  \n",
       "mean_categorical_imbalance                               0.632105    0.308063  \n",
       "std_categorical_imbalance                                0.286572    0.228906  \n",
       "skewness_mean                                            0.000000    0.255076  \n",
       "skewness_std                                             0.000000    1.420729  \n",
       "skewness_min                                             0.000000   -2.007217  \n",
       "skewness_max                                             0.000000    3.318064  \n",
       "kurtosis_mean                                            0.000000    2.046258  \n",
       "kurtosis_std                                             0.000000    4.890029  \n",
       "kurtosis_min                                             0.000000   -2.035406  \n",
       "kurtosis_max                                             0.000000   13.193069  \n",
       "total_values                                        115056.000000  912.000000  \n",
       "percentage_n_a                                           0.000000    0.357456  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import openml\n",
    "\n",
    "from amltk.metalearning import compute_metafeatures\n",
    "\n",
    "def get_dataset(dataset_id: int) -> tuple[pd.DataFrame, pd.Series]:\n",
    "    dataset = openml.datasets.get_dataset(\n",
    "        dataset_id,\n",
    "        download_data=True,\n",
    "        download_features_meta_data=False,\n",
    "        download_qualities=False,\n",
    "    )\n",
    "    X, y, _, _ = dataset.get_data(\n",
    "        dataset_format=\"dataframe\",\n",
    "        target=dataset.default_target_attribute,\n",
    "    )\n",
    "    return X, y\n",
    "\n",
    "d31 = get_dataset(31)\n",
    "d3 = get_dataset(3)\n",
    "d4 = get_dataset(4)\n",
    "\n",
    "metafeatures_dict = {\n",
    "    \"dataset_31\": compute_metafeatures(*d31),\n",
    "    \"dataset_3\": compute_metafeatures(*d3),\n",
    "    \"dataset_4\": compute_metafeatures(*d4),\n",
    "}\n",
    "\n",
    "metafeatures = pd.DataFrame(metafeatures_dict)\n",
    "metafeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5501986e",
   "metadata": {},
   "source": [
    "Ahora queremos conocer cuales `dataset_3` o `dataset_4` es similar a `dataset_31`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7913d1c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_4    19111.283139\n",
      "dataset_3    95081.367356\n",
      "Name: l2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from amltk.metalearning import dataset_distance\n",
    "\n",
    "# extraer los meta-features del dataset31\n",
    "target = metafeatures_dict.pop(\"dataset_31\")\n",
    "\n",
    "# en others ahora estan el resto, menos dataset31\n",
    "others = metafeatures_dict\n",
    "\n",
    "# calcula la distancia entre datasets, usado distancia euclidiana entre los vectores de metafeatures\n",
    "distances = dataset_distance(target, others, distance_metric=\"l2\")\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0976e6",
   "metadata": {},
   "source": [
    "Es necesario escalar los meta-features porque los valores altos dominan la distancia Euclidiana, mientras que otras entre 0 y 1 tiene muy poco peso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07b65317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_3    3.397475\n",
      "dataset_4    3.624972\n",
      "Name: l2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "distances_scaled = dataset_distance(\n",
    "    target,\n",
    "    others,\n",
    "    distance_metric=\"l2\",\n",
    "    scaler = \"minmax\" # aplicar min-max scaling sobre las filas\n",
    ")\n",
    "\n",
    "print(distances_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027412c2",
   "metadata": {},
   "source": [
    "Podemos ver que `dataset_3` es mas cercano a `dataset_31`. podemos usar tambien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1f3d7cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_3    3.397475\n",
      "dataset_4    3.624972\n",
      "Name: l2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "distances = dataset_distance(\n",
    "    target,\n",
    "    others,\n",
    "    distance_metric=\"l2\",\n",
    "    scaler=MinMaxScaler()\n",
    ")\n",
    "print(distances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65610c7f",
   "metadata": {},
   "source": [
    "# Portfolio Selection\n",
    "\n",
    "Un portafolio en meta-learning es un conjunto de configuraciones que maximiza alguna nocion de cobertura sobre diferentes datasets o tareas.La intuición detrás de esto es que, de esta forma, cualquier nuevo dataset también quedará cubierto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "80fc73e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           c1  c2  c3  c4\n",
      "dataset_1  90  20  10  90\n",
      "dataset_2  60  10  20  10\n",
      "dataset_3  20  90  40  10\n",
      "dataset_4  10  20  90  10\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "performances = {\n",
    "    \"c1\": [90, 60, 20, 10],\n",
    "    \"c2\": [20, 10, 90, 20],\n",
    "    \"c3\": [10, 20, 40, 90],\n",
    "    \"c4\": [90, 10, 10, 10],\n",
    "}\n",
    "\n",
    "portfolio = pd.DataFrame(performances, index=[\"dataset_1\", \"dataset_2\", \"dataset_3\", \"dataset_4\"])\n",
    "print(portfolio)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad25a88",
   "metadata": {},
   "source": [
    "Vemos aqui que tenemos 4 datasets y sus evaluaciones en 4 configuraciones. Ahora queremos `k=3` de esas configuraiones. La idea es seleccionar un subconjunto de estos algoritmos que maximice algún valor de utilidad del portafolio.\n",
    "\n",
    "Esto se hace agregando una sola configuración del conjunto completo, una por una, hasta alcanzar k, comenzando desde un portafolio vacío."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0429aa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              c1     c3     c2\n",
      "dataset_1  1.000  0.000  0.125\n",
      "dataset_2  1.000  0.200  0.000\n",
      "dataset_3  0.125  0.375  1.000\n",
      "dataset_4  0.000  1.000  0.125\n",
      "\n",
      "c1    0.53125\n",
      "c3    0.84375\n",
      "c2    1.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from amltk.metalearning import portfolio_selection\n",
    "\n",
    "selected_portfolio, trajectory = portfolio_selection(\n",
    "    portfolio,\n",
    "    k=3,\n",
    "    scaler=\"minmax\"\n",
    ")\n",
    "\n",
    "print(selected_portfolio)\n",
    "print()\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8414fb83",
   "metadata": {},
   "source": [
    "La trayectoria nos indica qué configuración fue añadida en cada instante de tiempo, junto con la utilidad del portafolio después de añadir dicha configuración.\n",
    "\n",
    "Sin embargo, no hemos especificado aún cómo se define exactamente la utilidad de un portafolio dado.\n",
    "\n",
    "Podemos definir nuestra propia función para hacerlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "18786746",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              c1     c3     c2\n",
      "dataset_1  1.000  0.000  0.125\n",
      "dataset_2  1.000  0.200  0.000\n",
      "dataset_3  0.125  0.375  1.000\n",
      "dataset_4  0.000  1.000  0.125\n",
      "\n",
      "c1    0.53125\n",
      "c3    0.84375\n",
      "c2    1.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "def my_function(p: pd.DataFrame) -> float:\n",
    "    # Take the maximum score for each dataset and then take the mean across them.\n",
    "    return p.max(axis=1).mean()\n",
    "\n",
    "selected_portfolio, trajectory = portfolio_selection(\n",
    "    portfolio,\n",
    "    k=3,\n",
    "    scaler=\"minmax\",\n",
    "    portfolio_value=my_function,\n",
    ")\n",
    "\n",
    "print(selected_portfolio)\n",
    "print()\n",
    "print(trajectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304b5a9d",
   "metadata": {},
   "source": [
    "Esta noción de reducir (agregar) primero sobre todas las configuraciones para cada dataset y luego agregar esos resultados es lo suficientemente común como para que también podamos definir directamente estas operaciones, y el resto se realizará automáticamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6cd2f27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              c1     c3     c2\n",
      "dataset_1  1.000  0.000  0.125\n",
      "dataset_2  1.000  0.200  0.000\n",
      "dataset_3  0.125  0.375  1.000\n",
      "dataset_4  0.000  1.000  0.125\n",
      "\n",
      "c1    0.53125\n",
      "c3    0.84375\n",
      "c2    1.00000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "selected_portfolio, trajectory = portfolio_selection(\n",
    "    portfolio,\n",
    "    k=3,\n",
    "    scaler=\"minmax\",\n",
    "    row_reducer=np.max,  # Reduce los valores por fila tomando el máximo (por dataset) (default)\n",
    "    aggregator=np.mean,  # Agrega los valores de todos los datasets tomando la media (default)\n",
    ")\n",
    "\n",
    "print(selected_portfolio)\n",
    "print()\n",
    "print(trajectory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
