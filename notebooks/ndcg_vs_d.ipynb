{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "51e94760",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import (\n",
    "    MetaFeatX, \n",
    "    get_cost_matrix, \n",
    "    intrinsic_estimator,\n",
    "    train_fused_gromov_wasserstein, get_ndcg_score)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from experiment import (\n",
    "    load_bootstrap_representations,\n",
    "    load_basic_representations,\n",
    "    load_target_representations\n",
    ")\n",
    "from sklearn.metrics import pairwise_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "389a2476",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetaFeatXCustom(MetaFeatX):\n",
    "    def __init__(self,d_value,**kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.d_value = d_value\n",
    "\n",
    "    \n",
    "    def train(\n",
    "        self, \n",
    "        basic_reprs: pd.DataFrame, \n",
    "        target_reprs: pd.DataFrame,\n",
    "        column_id: str\n",
    "    ) -> None:\n",
    "\n",
    "        # ordena todas las tareas unicas de basic_reprs\n",
    "        list_ids = sorted(list(basic_reprs[column_id].unique()))\n",
    "\n",
    "        # comprueba que todas estas tareas tengan representationes objetivo\n",
    "        task_id_has_target_representation = target_reprs[column_id].unique()\n",
    "        if set(list_ids) != set(task_id_has_target_representation):\n",
    "            raise ValueError(\"Inconsistent numbers of instances.\")\n",
    "\n",
    "        # se guarda una lista de features basicas\n",
    "        basic_repr_labels = basic_reprs.columns\n",
    "        self.basic_repr_labels = [str(_) for _ in basic_repr_labels if _ != column_id]\n",
    "        \n",
    "        self.cost_matrix = get_cost_matrix(\n",
    "            target_repr=target_reprs,\n",
    "            task_ids=list_ids,\n",
    "            verbose=self.verbose,\n",
    "            ncpus=self.ncpus,\n",
    "        )\n",
    "\n",
    "        assert self.cost_matrix.shape[0] == len(list_ids)\n",
    "    \n",
    "        # print(f\"Cost matrix:\\n{self.cost_matrix}\")\n",
    "\n",
    "        # estimacion de la dimension intrinseca\n",
    "        if self.d_value == 100:\n",
    "            self.intrinsic_dim = intrinsic_estimator(self.cost_matrix)\n",
    "            print(f\"Intrinsic dimension: {self.intrinsic_dim}\")\n",
    "        else :\n",
    "            self.intrinsic_dim = self.d_value\n",
    "\n",
    "        # Aprendizaje de la representacion del modelo\n",
    "        self.model, self.mds = train_fused_gromov_wasserstein(\n",
    "            basic_representations=basic_reprs.set_index(column_id),\n",
    "            pairwise_dist_z=self.cost_matrix,\n",
    "            learning_rate=self.learning_rate,\n",
    "            seed=self.seed,\n",
    "            early_stopping=self.early_stopping_patience,\n",
    "            early_stopping_criterion_ndcg=self.early_stopping_criterion_ndcg,\n",
    "            alpha=self.alpha,\n",
    "            intrinsic_dim=self.intrinsic_dim,\n",
    "            lambda_reg=self.lambda_reg,\n",
    "            device=self.device,\n",
    "            list_ids=list_ids,\n",
    "        )\n",
    "\n",
    "        print(f\"Trained linear mapping shape: {self.linear_mapping.shape}\")\n",
    "        # print(f\"Trainerd linear mapping:\\n{self.model.shape}\")\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ac31f512",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_model_representations(cfg, basic_reprs, target_reprs, list_ids, train_ids, test_ids, d):\n",
    "    basic_reprs[\"boostrap\"] = 0\n",
    "\n",
    "    bootstrap_reprs = load_bootstrap_representations(metafeature=cfg.metafeature, path=cfg.data_path)\n",
    "\n",
    "    print(bootstrap_reprs.shape)\n",
    "    bootstrap_reprs = bootstrap_reprs[bootstrap_reprs.task_id.isin(list_ids)]\n",
    "\n",
    "    \n",
    "    bootstrap_reprs[\"boostrap\"] = 1\n",
    "\n",
    "    print(bootstrap_reprs.shape)\n",
    "\n",
    "    combined_basic_reprs = pd.concat([basic_reprs, bootstrap_reprs], axis=0)\n",
    "\n",
    "    print(combined_basic_reprs.shape)\n",
    "\n",
    "    \n",
    "    combined_basic_reprs = pd.concat([\n",
    "        combined_basic_reprs[combined_basic_reprs.task_id.isin(train_ids)],\n",
    "        combined_basic_reprs[combined_basic_reprs.task_id.isin(test_ids)]\n",
    "    ], axis=0)\n",
    "\n",
    "    print(combined_basic_reprs.shape)\n",
    "    \n",
    "\n",
    "    model = MetaFeatXCustom(d_value=d,\n",
    "                    alpha=0.5,\n",
    "                    lambda_reg=1e-3,\n",
    "                    learning_rate=0.01,\n",
    "                    early_stopping_patience=20,\n",
    "                    early_stopping_criterion_ndcg=cfg.task.ndcg,\n",
    "                    verbose=False,\n",
    "                    seed=cfg.seed)\n",
    "    \n",
    "    repr_train, repr_test = model.train_and_predict(\n",
    "        basic_reprs=combined_basic_reprs.drop([\"boostrap\"], axis=1),\n",
    "        target_reprs=target_reprs,\n",
    "        column_id=\"task_id\",\n",
    "        train_ids=train_ids,\n",
    "        test_ids=test_ids\n",
    "    )\n",
    "\n",
    "    model_reprs = np.concatenate([repr_train, repr_test], axis=0)\n",
    "    model_reprs = pd.DataFrame(model_reprs, columns=[f\"col{_}\" for _ in range(model_reprs.shape[1])])\n",
    "    model_reprs[\"task_id\"] = combined_basic_reprs[\"task_id\"].values\n",
    "    model_reprs[\"boostrap\"] = combined_basic_reprs[\"boostrap\"].values\n",
    "    return model_reprs[model_reprs.boostrap == 0].drop([\"boostrap\"], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "23546c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_task1(cfg,d):\n",
    "\n",
    "    target_reprs = load_target_representations(pipeline=cfg.pipeline, path=cfg.data_path)\n",
    "\n",
    "    list_ids = sorted(list(target_reprs[\"task_id\"].unique()))\n",
    "\n",
    "    if cfg.openml_tid not in list_ids:\n",
    "        raise Exception(f\"OpenML task {cfg.openml_tid} does not have target representations.\")\n",
    "\n",
    "    basic_reprs = load_basic_representations(metafeature=cfg.metafeature, path=cfg.data_path)\n",
    "\n",
    "    basic_reprs = basic_reprs[basic_reprs.task_id.isin(list_ids)]\n",
    "\n",
    "    if cfg.metafeature.name == \"metafeatx\":\n",
    "        train_ids = [_ for _ in list_ids if _ != cfg.openml_tid]\n",
    "        test_ids = [cfg.openml_tid]\n",
    "\n",
    "        basic_reprs = load_model_representations(cfg, basic_reprs, target_reprs, list_ids, train_ids, test_ids,d)\n",
    "\n",
    "    basic_reprs = basic_reprs.set_index(\"task_id\")\n",
    "\n",
    "    true_dist = get_cost_matrix(target_repr=target_reprs, task_ids=list_ids, verbose=False)\n",
    "    pred_dist = pairwise_distances(basic_reprs.loc[list_ids])\n",
    "\n",
    "\n",
    "    id_test = list_ids.index(cfg.openml_tid)\n",
    "\n",
    "    return get_ndcg_score(dist_pred=np.array([pred_dist[id_test]]), dist_true=np.array([true_dist[id_test]]),\n",
    "                       k=cfg.task.ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "808a456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de datsets usados\n",
    "datasets_has_priors = [\n",
    "    3, 6, 11, 12, 14, 15, 16, 18, 22, 23, 28, 29, 31, 32, 37, 43, 45, 49,\n",
    "    53, 219, 2074, 2079, 3021, 3022, 3481, 3549, 3560, 3573, 3902, 3903,\n",
    "    3904, 3913, 3917, 3918, 7592, 9910, 9946, 9952, 9957, 9960, 9964, 9971,\n",
    "    9976, 9977, 9978, 9981, 9985, 10093, 10101, 14952, 14954, 14965, 14969,\n",
    "    14970, 125920, 125922, 146195, 146800, 146817, 146819, 146820, 146821,\n",
    "    146824, 167125\n",
    "]\n",
    "assert len(datasets_has_priors) == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6fad57a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "def compute(dataset,cfg_metafeature, cfg_pipeline,cfg_main,cfg_task):\n",
    "\n",
    "    cfg = OmegaConf.create({\n",
    "        \"seed\": cfg_main.get(\"seed\", 42),\n",
    "        \"pipeline\": cfg_pipeline,\n",
    "        \"metafeature\": cfg_metafeature,\n",
    "        \"task\": cfg_task,\n",
    "        \"openml_tid\": cfg_main.get(\"openml_tid\", dataset),\n",
    "        \"data_path\": cfg_main.get(\"data_path\", \"../data\"),\n",
    "        \"output_file\": cfg_main.get(\"output_file\", None),\n",
    "    })\n",
    "\n",
    "\n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "1df1488a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def config( pipeline_name, config_base_path=\"../conf\",task_name=\"task1\"):\n",
    "    # Config general\n",
    "    config_yaml = os.path.join(config_base_path, \"config.yaml\")\n",
    "    cfg_main = OmegaConf.load(config_yaml)\n",
    "\n",
    "    # Pipeline\n",
    "    pipeline_yaml = os.path.join(config_base_path, \"pipeline\", f\"{pipeline_name}.yaml\")\n",
    "    cfg_pipeline = OmegaConf.load(pipeline_yaml)\n",
    "\n",
    "    # Metafeature\n",
    "    metafeature_yaml = os.path.join(config_base_path, \"metafeature\", \"metafeatx.yaml\")\n",
    "    cfg_metafeature = OmegaConf.load(metafeature_yaml)\n",
    "\n",
    "    # Task\n",
    "    task_yaml = os.path.join(config_base_path, \"task\", f\"{task_name}.yaml\")\n",
    "    cfg_task = OmegaConf.load(task_yaml)\n",
    "\n",
    "    return cfg_main,cfg_pipeline, cfg_task, cfg_metafeature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbde7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==2 ---- dataset random==146824\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==5 ---- dataset random==9978\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==10 ---- dataset random==14970\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (10, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==15 ---- dataset random==23\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (15, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==20 ---- dataset random==3904\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (20, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==25 ---- dataset random==14952\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (25, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==10 ---- dimension==100 ---- dataset random==12\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Intrinsic dimension: 8\n",
      "Trained linear mapping shape: (8, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==2 ---- dataset random==3021\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==5 ---- dataset random==125920\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==10 ---- dataset random==32\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (10, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==15 ---- dataset random==3573\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (15, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==20 ---- dataset random==12\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (20, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==25 ---- dataset random==3481\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (25, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==15 ---- dimension==100 ---- dataset random==29\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Intrinsic dimension: 8\n",
      "Trained linear mapping shape: (8, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==2 ---- dataset random==125920\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==5 ---- dataset random==219\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==10 ---- dataset random==9971\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (10, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==15 ---- dataset random==37\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (15, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==20 ---- dataset random==3573\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (20, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==25 ---- dataset random==9964\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (25, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==20 ---- dimension==100 ---- dataset random==9964\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Intrinsic dimension: 8\n",
      "Trained linear mapping shape: (8, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==2 ---- dataset random==7592\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==5 ---- dataset random==3917\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==10 ---- dataset random==53\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (10, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==15 ---- dataset random==146817\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (15, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==20 ---- dataset random==146824\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (20, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==25 ---- dataset random==2079\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (25, 135)\n",
      "PIPELINE ==adaboost ---- NDCG@K==25 ---- dimension==100 ---- dataset random==37\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Intrinsic dimension: 8\n",
      "Trained linear mapping shape: (8, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==2 ---- dataset random==14970\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==5 ---- dataset random==125922\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==10 ---- dataset random==146800\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (10, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==15 ---- dataset random==9964\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (15, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==20 ---- dataset random==9981\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (20, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==25 ---- dataset random==14965\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (25, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==10 ---- dimension==100 ---- dataset random==16\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Intrinsic dimension: 12\n",
      "Trained linear mapping shape: (12, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==15 ---- dimension==2 ---- dataset random==9946\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (2, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==15 ---- dimension==5 ---- dataset random==18\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n",
      "Trained linear mapping shape: (5, 135)\n",
      "PIPELINE ==random_forest ---- NDCG@K==15 ---- dimension==10 ---- dataset random==146800\n",
      "(72000, 136)\n",
      "(64000, 137)\n",
      "(64064, 137)\n",
      "(64064, 137)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "pipelines = ['adaboost','random_forest','libsvm_svc']\n",
    "k_values = [10,15,20,25]\n",
    "d_values = [2,5,10,15,20,25,100]\n",
    "\n",
    "results = defaultdict(lambda: defaultdict(dict))  # 2 niveles por default\n",
    "\n",
    "for pipeline in pipelines:\n",
    "    \n",
    "    for k_value in k_values:\n",
    "        for d in d_values:\n",
    "            # escogemos un dataset aleatorio\n",
    "            dataset_id = random.choice(datasets_has_priors)\n",
    "            print(f\"PIPELINE =={pipeline} ---- NDCG@K=={k_value} ---- dimension=={d} ---- dataset random=={dataset_id}\")\n",
    "\n",
    "            cfg_main, cfg_pipeline, cfg_task, cfg_metafeature = config(pipeline_name=pipeline)\n",
    "            \n",
    "            cfg.task.ndcg = k_value\n",
    "            \n",
    "            # generamos la configuración para ese dataset\n",
    "            cfg = compute(\n",
    "                dataset=dataset_id,\n",
    "                cfg_metafeature=cfg_metafeature, \n",
    "                cfg_pipeline=cfg_pipeline,\n",
    "                cfg_main=cfg_main,\n",
    "                cfg_task=cfg_task\n",
    "            )\n",
    "            \n",
    "            \n",
    "            value_ndcg = run_task1(cfg=cfg, d=d)  # retorna un valor para ese dataset\n",
    "            \n",
    "            # guardamos el valor (media y std son iguales porque solo hay 1 dataset)\n",
    "            results[pipeline][k_value][d] = {\n",
    "                'mean': float(value_ndcg),\n",
    "                'std': 0.0  # sin variación, solo 1 valor\n",
    "            }\n",
    "\n",
    "print(results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
