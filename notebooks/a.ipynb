{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# agregar la carpeta padre de notebook y model al path\n",
    "sys.path.append(os.path.abspath(\"..\"))\n",
    "\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from model import get_cost_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da23d0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Lista de datsets usados\n",
    "datasets_has_priors = [\n",
    "    3, 6, 11, 12, 14, 15, 16, 18, 22, 23, 28, 29, 31, 32, 37, 43, 45, 49,\n",
    "    53, 219, 2074, 2079, 3021, 3022, 3481, 3549, 3560, 3573, 3902, 3903,\n",
    "    3904, 3913, 3917, 3918, 7592, 9910, 9946, 9952, 9957, 9960, 9964, 9971,\n",
    "    9976, 9977, 9978, 9981, 9985, 10093, 10101, 14952, 14954, 14965, 14969,\n",
    "    14970, 125920, 125922, 146195, 146800, 146817, 146819, 146820, 146821,\n",
    "    146824, 167125\n",
    "]\n",
    "assert len(datasets_has_priors) == 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d017cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrac_matrix_distance(basic_reprs, target_reprs,column_id):\n",
    "     # ordena todas las tareas unicas de basic_reprs\n",
    "    list_ids = sorted(list(basic_reprs[column_id].unique()))\n",
    "\n",
    "        # comprueba que todas estas tareas tengan representationes objetivo\n",
    "    task_id_has_target_representation = target_reprs[column_id].unique()\n",
    "    if set(list_ids) != set(task_id_has_target_representation):\n",
    "        raise ValueError(\"Inconsistent numbers of instances.\")\n",
    "\n",
    "        # se guarda una lista de features basicas\n",
    "    basic_repr_labels = basic_reprs.columns\n",
    "    basic_repr_labels = [str(_) for _ in basic_repr_labels if _ != column_id]\n",
    "        \n",
    "    cost_matrix = get_cost_matrix(\n",
    "            target_repr=target_reprs,\n",
    "            task_ids=list_ids,\n",
    "            verbose= False,\n",
    "            ncpus=1,\n",
    "    )\n",
    "\n",
    "    assert cost_matrix.shape[0] == len(list_ids)\n",
    "\n",
    "\n",
    "    return cost_matrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef95ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def intrinsic_estimator(matrix_distance):\n",
    "    muL = []\n",
    "    N = len(matrix_distance)\n",
    "    Femp = []\n",
    "\n",
    "    #itera por cada task de la matriz\n",
    "    for i in range(len(matrix_distance)):\n",
    "        distances_ = np.unique(matrix_distance[i])\n",
    "\n",
    "        # toma los dos vecinos mas cercanos\n",
    "        NN = np.argsort(distances_)[1:3]\n",
    "        first = NN[0]\n",
    "        second = NN[1]\n",
    "\n",
    "        # calcula ratio (invariante a escala y tiene distribucion conocida segun la dimension)\n",
    "        mu_i = distances_[second] / (distances_[first] + (10 ** (-3)))\n",
    "        muL.append(mu_i)\n",
    "\n",
    "    # limpiar outliers (elimina el 10% mas grande)\n",
    "    muL = np.sort(muL)\n",
    "\n",
    "    \n",
    "    cutoff = int(np.floor(0.9 * len(muL)))\n",
    "\n",
    "    if len(muL) > 10:\n",
    "\n",
    "        muL = muL[0 : cutoff + 1]\n",
    "    \n",
    "    else:\n",
    "        muL = muL[0:cutoff]\n",
    "\n",
    "    # evitar valor invalidos(para el log)\n",
    "    muL = [x if x > 0 else 1 + 10 ** (-3) for x in muL]\n",
    "\n",
    "    # transformacion logaritmica\n",
    "    muL = np.asarray([math.log(mu_i) for mu_i in muL]).reshape(-1, 1)\n",
    "    \n",
    "    # construccion de al cdf empirica\n",
    "    step = 1 / N\n",
    "    Femp = [i * step for i in range(1, len(muL) + 1)]\n",
    "    Femp = np.asarray([-math.log(1 - x) for x in Femp]).reshape(-1, 1)\n",
    "\n",
    "    # Regresion lineal (sin intercepto) para estimar la dimension intrinseca\n",
    "    clf = LinearRegression(fit_intercept=False)\n",
    "    clf.fit(muL, Femp)\n",
    "\n",
    "    # extraer la dimension\n",
    "    return clf.coef_[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf4db29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_data(basic_path, target_path):\n",
    "    \"\"\"\n",
    "    Carga y normaliza las representaciones básicas y las representaciones objetivo.\n",
    "    \"\"\"\n",
    "    # Cargar datasets\n",
    "    basic_representations = pd.read_csv(basic_path).fillna(0)\n",
    "    target_representations = pd.read_csv(target_path)\n",
    "    \n",
    "    # Filtrar tareas que existen en el target\n",
    "    basic_representations = basic_representations[\n",
    "        basic_representations.task_id.isin(target_representations.task_id.unique())\n",
    "    ]\n",
    "    \n",
    "    # Normalizar meta-features (excepto la columna task_id)\n",
    "    cols = basic_representations.columns.drop(\"task_id\")\n",
    "    scaler = StandardScaler()\n",
    "    basic_representations[cols] = scaler.fit_transform(basic_representations[cols])\n",
    "    \n",
    "    return basic_representations, target_representations, scaler, cols\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d452cdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_basic_target_representations(pipeline):\n",
    "    basic_representations, target_representations, scaler, cols = load_and_preprocess_data(\n",
    "        basic_path=\"../data/basic_representations.csv\",\n",
    "        target_path=f\"../data/{pipeline}_target_representation.csv\"\n",
    "    )\n",
    "\n",
    "    return basic_representations, target_representations,scaler, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9433ecd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# ratios_np = np.array(ratios)\n",
    "\n",
    "# plt.figure()\n",
    "\n",
    "# for pipeline in pipelines:\n",
    "#     means = [results[pipeline][r][\"mean\"] for r in ratios]\n",
    "#     stds = [results[pipeline][r][\"std\"] for r in ratios]\n",
    "\n",
    "#     plt.errorbar(\n",
    "#         ratios_np,\n",
    "#         means,\n",
    "#         yerr=stds,\n",
    "#         marker='o',\n",
    "#         capsize=5,\n",
    "#         label=pipeline\n",
    "#     )\n",
    "\n",
    "# plt.xlabel(\"Dataset ratio\")\n",
    "# plt.ylabel(\"Intrinsic dimension (mean ± std)\")\n",
    "# plt.title(\"Intrinsic Dimension vs Dataset Ratio per Pipeline\")\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # Construir la matriz de strings\n",
    "# cell_text = []\n",
    "# for pipeline in pipelines:\n",
    "#     row = []\n",
    "#     for ratio in ratios:\n",
    "#         mean = results[pipeline][ratio][\"mean\"]\n",
    "#         std  = results[pipeline][ratio][\"std\"]\n",
    "#         row.append(f\"{mean:.2f} ({std:.2f})\")\n",
    "#     cell_text.append(row)\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# ax.axis('off')\n",
    "\n",
    "# table = ax.table(\n",
    "#     cellText=cell_text,\n",
    "#     rowLabels=pipelines,\n",
    "#     colLabels=[str(r) for r in ratios],\n",
    "#     loc='center'\n",
    "# )\n",
    "\n",
    "# table.auto_set_font_size(False)\n",
    "# table.set_fontsize(10)\n",
    "# table.scale(1.2, 1.5)\n",
    "\n",
    "# ax.set_title(\"Intrinsic Dimension: mean (std)\")\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fe4c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = [0.1, 0.25, 0.5,0.75,1]\n",
    "pipelines = ['adaboost','random_forest', 'autosklearn', 'libsvm_svc']\n",
    "results = defaultdict(dict)\n",
    "n_repeats = 20\n",
    "\n",
    "\n",
    "for pipeline in pipelines:\n",
    "\n",
    "\n",
    "    basic,target,_, cols = get_basic_target_representations(pipeline)\n",
    "\n",
    "    for ratio in ratios:\n",
    "\n",
    "        if ratio <= 0.25:\n",
    "            n_repeats = np.random.randint(25, 31)\n",
    "        elif ratio <= 0.75:\n",
    "            n_repeats = np.random.randint(10, 16)\n",
    "        else :\n",
    "            n_repeats = 1\n",
    "\n",
    "        intrinsic_values = []\n",
    "\n",
    "        n_samples = int(len(datasets_has_priors) * ratio)\n",
    "        \n",
    "        print(f\"PIPELINE =={pipeline} ---- RATIO=={ratio} ---- n_repeats=={n_repeats}\")\n",
    "\n",
    "        for _ in range(n_repeats):\n",
    "\n",
    "            task_ids_subset = random.sample(datasets_has_priors, n_samples)\n",
    "\n",
    "            basic_subset = basic[basic[\"task_id\"].isin(task_ids_subset)].copy()\n",
    "            target_subset = target[target[\"task_id\"].isin(task_ids_subset)].copy()\n",
    "\n",
    "            assert len(basic_subset) == n_samples\n",
    "            \n",
    "            cost_matrix = extrac_matrix_distance(\n",
    "                                basic_reprs=basic_subset, \n",
    "                                target_reprs=target_subset, \n",
    "                                column_id=\"task_id\")   \n",
    "            \n",
    "            intrinsic_dim = intrinsic_estimator(cost_matrix)\n",
    "            #print(f\"Intrinsic dimension: {intrinsic_dim}\")\n",
    "            intrinsic_values.append(intrinsic_dim)\n",
    "\n",
    "        \n",
    "        mean_dim = np.mean(intrinsic_values)\n",
    "        std_dim = np.std(intrinsic_values)\n",
    "\n",
    "        results[pipeline][ratio] = {\"mean\": mean_dim, \"std\": std_dim}\n",
    "\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
