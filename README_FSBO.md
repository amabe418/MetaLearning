# FSBO: Few-Shot Bayesian Optimization para Optimizaci√≥n de Hiperpar√°metros

Sistema de **Transfer Learning** para optimizaci√≥n de hiperpar√°metros usando **Few-Shot Bayesian Optimization (FSBO)**.

## üéØ Problema

La **optimizaci√≥n de hiperpar√°metros (HPO)** es costosa:
- Cada evaluaci√≥n requiere entrenar un modelo completo
- Los espacios de b√∫squeda son grandes
- Empezar desde cero en cada nuevo dataset es ineficiente

**Soluci√≥n**: Usar conocimiento de tareas previas (transfer learning) para optimizar m√°s r√°pido en nuevas tareas.

## üß† ¬øQu√© es FSBO?

FSBO (Few-Shot Bayesian Optimization) es un m√©todo que:

1. **Pre-entrena** un modelo surrogate (Deep Kernel GP) en m√∫ltiples tareas
2. **Transfiere** el conocimiento a nuevas tareas
3. **Optimiza** con pocas evaluaciones gracias al conocimiento previo

**Paper**: Wistuba & Grabocka (2021) - *Few-Shot Bayesian Optimization with Deep Kernel Surrogates* (ICLR)

## üìÅ Estructura del Proyecto

```
transfer-learning/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ configspace/                    # Espacios de hiperpar√°metros
‚îÇ   ‚îî‚îÄ‚îÄ representation_with_scores/     # Datos con m√©tricas
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ generate_synthetic_scores.py    # Generador de datos
‚îÇ   ‚îú‚îÄ‚îÄ train_fsbo.py                   # Entrenamiento del modelo
‚îÇ   ‚îú‚îÄ‚îÄ fsbo_optimizer.py               # API observe/suggest
‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                      # M√©tricas de evaluaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ baselines.py                    # M√©todos de comparaci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ experiments.py                  # Framework K-Fold CV
‚îÇ   ‚îî‚îÄ‚îÄ visualize.py                    # Visualizaciones
‚îú‚îÄ‚îÄ experiments/
‚îÇ   ‚îú‚îÄ‚îÄ checkpoints/                    # Modelos entrenados
‚îÇ   ‚îú‚îÄ‚îÄ results/                        # Resultados JSON
‚îÇ   ‚îî‚îÄ‚îÄ figures/                        # Gr√°ficos
‚îú‚îÄ‚îÄ doc/
‚îÇ   ‚îú‚îÄ‚îÄ technical_report.pdf            # Documentaci√≥n t√©cnica
‚îÇ   ‚îî‚îÄ‚îÄ experimental_report.pdf         # Resultados experimentales
‚îî‚îÄ‚îÄ requirements.txt
```

## üöÄ Instalaci√≥n

```bash
# Clonar repositorio
git clone https://github.com/usuario/MetaLearning-.git
cd MetaLearning-/transfer-learning

# Crear entorno virtual (opcional)
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o: venv\Scripts\activate  # Windows

# Instalar dependencias
pip install -r requirements.txt
```

## üì¶ Dependencias

```
numpy>=1.21.0
pandas>=1.3.0
scikit-learn>=1.0.0
scipy>=1.7.0
torch>=1.10.0
gpytorch>=1.6.0
tqdm>=4.62.0
matplotlib>=3.5.0
```

## üíª Uso

### 1. Entrenar el modelo FSBO

```bash
# Entrenar para un algoritmo espec√≠fico
python scripts/train_fsbo.py --algorithm adaboost --epochs 2000

# Entrenar para todos los algoritmos
python scripts/train_fsbo.py --algorithm all
```

### 2. Usar el optimizador (API observe/suggest)

```python
from fsbo_optimizer import FSBOOptimizer

# Cargar modelo pre-entrenado
optimizer = FSBOOptimizer.from_pretrained('random_forest')

# Warm start: configuraciones iniciales prometedoras
initial_configs = optimizer.suggest_initial(n=5)
for config in initial_configs:
    score = train_and_evaluate(model, config)
    optimizer.observe(config, score)

# Loop de optimizaci√≥n
for _ in range(25):
    config = optimizer.suggest()           # Sugerir siguiente config
    score = train_and_evaluate(model, config)
    optimizer.observe(config, score)       # Registrar resultado

# Obtener mejor configuraci√≥n
best_config, best_score = optimizer.get_best()
```

### 3. Ejecutar experimentos

```bash
# Experimento completo con K-Fold CV
python scripts/experiments.py \
    --algorithm all \
    --k_folds 5 \
    --n_trials 30 \
    --n_seeds 3 \
    --methods fsbo random gp-rs

# Generar visualizaciones
python scripts/visualize.py \
    --results experiments/results/ \
    --output experiments/figures/
```

## üìä Resultados

FSBO supera consistentemente a los baselines en todos los algoritmos evaluados:

| Algoritmo | FSBO (NR‚Üì) | Random | GP-RS |
|-----------|------------|--------|-------|
| AdaBoost | **0.189** | 0.195 | 0.197 |
| Random Forest | **0.230** | 0.253 | 0.259 |
| LibSVM_SVC | **0.196** | 0.217 | 0.200 |
| AutoSklearn | **0.332** | 0.341 | 0.334 |

*NR = Normalized Regret (menor es mejor)*

## üîó Integraci√≥n con Meta-Learning

Este m√≥dulo est√° dise√±ado para integrarse con el componente de meta-learning:

```python
from fsbo_optimizer import optimize_algorithms

# Meta-learning sugiere algoritmos para el dataset
suggested_algorithms = meta_learner.suggest(X, y)
# -> ['random_forest', 'adaboost']

# FSBO optimiza hiperpar√°metros de cada uno
results = optimize_algorithms(
    algorithms=suggested_algorithms,
    evaluation_fn=lambda alg, hp: train_evaluate(X, y, alg, hp),
    budget_per_algorithm=30
)

# Mejor combinaci√≥n (algoritmo + hiperpar√°metros)
best_alg = max(results, key=lambda a: results[a].best_score)
print(f"Mejor: {best_alg} con {results[best_alg].best_config}")
```

## üìö Documentaci√≥n

- **[technical_report.pdf](doc/technical_report.pdf)**: Documentaci√≥n t√©cnica completa (17 p√°ginas)
- **[experimental_report.pdf](doc/experimental_report.pdf)**: An√°lisis de resultados experimentales
- **[EXPERIMENTS.md](doc/EXPERIMENTS.md)**: Gu√≠a del framework de experimentaci√≥n

## üß™ Algoritmos Soportados

- AdaBoost
- Random Forest
- LibSVM SVC
- AutoSklearn

## üìñ Referencias

```bibtex
@inproceedings{wistuba2021fsbo,
  title={Few-Shot Bayesian Optimization with Deep Kernel Surrogates},
  author={Wistuba, Martin and Grabocka, Josif},
  booktitle={International Conference on Learning Representations},
  year={2021}
}
```



Proyecto acad√©mico - MetaLearning

---

**Fecha**: Enero 2026

