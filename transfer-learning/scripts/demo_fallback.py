"""
Demo: CÃ³mo funciona el sistema sin Knowledge Base.

Muestra las estrategias de fallback cuando no hay datos histÃ³ricos.
"""

import numpy as np
from sklearn.datasets import make_classification
import sys
sys.path.insert(0, '.')

from pipeline import KnowledgeBase, DatasetMetaFeatures
from meta_learner import TransferLearningMetaLearner


def demo_sin_kb():
    """Demo con knowledge base vacÃ­a."""
    print("\n" + "=" * 70)
    print("ğŸ§ª DEMO: Sistema SIN Knowledge Base (Primera EjecuciÃ³n)")
    print("=" * 70)
    
    # 1. KB vacÃ­a
    kb = KnowledgeBase()  # No cargar archivo
    print(f"\nğŸ“¦ Knowledge Base: VACÃA ({len(kb.entries)} entradas)")
    
    # 2. Meta-learner con KB vacÃ­a
    meta_learner = TransferLearningMetaLearner(kb)
    
    # 3. Diferentes tipos de datasets
    datasets = [
        ("PequeÃ±o (100 samples, 5 features)", 
         make_classification(n_samples=100, n_features=5, n_informative=3, n_classes=2, random_state=1)),
        
        ("Grande (10000 samples, 10 features)",
         make_classification(n_samples=10000, n_features=10, n_informative=8, n_classes=2, random_state=2)),
        
        ("Alta dimensionalidad (500 samples, 100 features)",
         make_classification(n_samples=500, n_features=100, n_informative=20, n_classes=2, random_state=3)),
    ]
    
    for name, (X, y) in datasets:
        print(f"\n{'â”€' * 70}")
        print(f"ğŸ“Š Dataset: {name}")
        print(f"   Shape: {X.shape}")
        
        # Extraer meta-features
        meta_features = DatasetMetaFeatures.from_data(X, y, dataset_id=name)
        
        # Pedir sugerencias (sin KB)
        print(f"\nğŸ¤– Meta-Learner (sin datos histÃ³ricos):")
        suggestions = meta_learner.suggest_algorithms(meta_features, top_k=3)
        
        print(f"\nâœ¨ Sugerencias AJUSTADAS por caracterÃ­sticas del dataset:")
        for i, s in enumerate(suggestions, 1):
            print(f"   {i}. {s.name:<20} confianza={s.confidence:.3f}")
        
        # Explicar por quÃ©
        log_n_samples = meta_features.meta_vector[0]
        log_n_features = meta_features.meta_vector[1]
        n_samples = int(np.exp(log_n_samples))
        n_features = int(np.exp(log_n_features))
        
        print(f"\n   ğŸ’¡ HeurÃ­stica:")
        if n_samples < 500:
            print(f"      â€¢ Dataset pequeÃ±o ({n_samples}) â†’ Random Forest + AdaBoost")
        elif n_samples > 10000:
            print(f"      â€¢ Dataset grande ({n_samples}) â†’ Random Forest (escala bien)")
        
        if n_features > 50:
            print(f"      â€¢ Alta dimensionalidad ({n_features}) â†’ Gradient Boosting")
        elif n_features < 10:
            print(f"      â€¢ Baja dimensionalidad ({n_features}) â†’ Cualquier algoritmo")


def demo_estrategia_completa():
    """Muestra la estrategia completa de fallback."""
    print("\n" + "=" * 70)
    print("ğŸ“š ESTRATEGIA COMPLETA DE FALLBACK")
    print("=" * 70)
    
    print("""
ğŸ”„ NIVELES DE FALLBACK:

1ï¸âƒ£ IDEAL: Knowledge Base con tareas similares
   â”œâ”€ Buscar en KB
   â”œâ”€ Filtrar por similitud > threshold (0.5)
   â”œâ”€ Rankear por performance en tareas similares
   â”œâ”€ Warm start con configs reales
   â””â”€ âœ… Sugerencias basadas en DATOS REALES

2ï¸âƒ£ FALLBACK 1: KB existe pero no hay suficientemente similares
   â”œâ”€ Bajar threshold de similitud (0.5 â†’ 0.3)
   â”œâ”€ Si aÃºn no hay suficientes â†’ siguiente nivel
   â””â”€ Usar lo mejor disponible + heurÃ­sticas

3ï¸âƒ£ FALLBACK 2: KB vacÃ­a o sin tareas similares
   â”œâ”€ Sugerencias por defecto (RF, GB, AdaBoost)
   â”œâ”€ AJUSTAR por meta-features del dataset:
   â”‚  â”œâ”€ Dataset pequeÃ±o â†’ RF + AdaBoost â¬†ï¸
   â”‚  â”œâ”€ Dataset grande â†’ RF â¬†ï¸, GB â¬‡ï¸
   â”‚  â”œâ”€ Alta dimensionalidad â†’ GB â¬†ï¸
   â”‚  â””â”€ Baja dimensionalidad â†’ todos igual
   â””â”€ âœ… Sugerencias HEURÃSTICAS pero INTELIGENTES

4ï¸âƒ£ FALLBACK 3: Warm start sin KB
   â”œâ”€ No hay configs de tareas similares
   â”œâ”€ Usar modelo FSBO pre-entrenado
   â”‚  (entrenado en datos de OpenML)
   â””â”€ âœ… Mejor que RANDOM PURO

5ï¸âƒ£ ÃšLTIMO RECURSO: Sin modelo FSBO
   â”œâ”€ Random search puro
   â””â”€ âš ï¸ Menos eficiente pero funciona

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ’¡ LO IMPORTANTE:
   â€¢ El sistema SIEMPRE puede sugerir algo
   â€¢ Mejora automÃ¡ticamente con cada uso
   â€¢ Primera vez: heurÃ­sticas inteligentes
   â€¢ Segunda vez en adelante: transfer learning real

ğŸ”„ AUTO-MEJORA:
   1. Primera tarea â†’ Usa defaults + heurÃ­sticas
   2. Guarda resultado en KB
   3. Segunda tarea â†’ Ya tiene 1 entrada en KB
   4. Tercera tarea â†’ Empieza a hacer transfer real
   5. N-Ã©sima tarea â†’ KB rica, transfer muy efectivo âœ¨
    """)


def demo_mejora_progresiva():
    """Demo de cÃ³mo el sistema mejora con el tiempo."""
    print("\n" + "=" * 70)
    print("ğŸ“ˆ DEMO: MEJORA PROGRESIVA")
    print("=" * 70)
    
    kb = KnowledgeBase()
    meta_learner = TransferLearningMetaLearner(kb, similarity_threshold=0.3)
    
    # Simular 5 tareas sucesivas
    print("\nğŸ”„ Simulando 5 tareas consecutivas:\n")
    
    for i in range(1, 6):
        X, y = make_classification(
            n_samples=500 + i*100,
            n_features=20,
            n_informative=15,
            n_classes=2,
            random_state=i
        )
        
        meta_features = DatasetMetaFeatures.from_data(
            X, y, 
            dataset_id=f"task_{i}"
        )
        
        print(f"{'â”' * 70}")
        print(f"ğŸ“Š Tarea {i}: {X.shape[0]} samples, {X.shape[1]} features")
        print(f"   KB actual: {len(kb.entries)} entradas")
        
        # Sugerir
        suggestions = meta_learner.suggest_algorithms(meta_features, top_k=2)
        
        print(f"   Sugerencias:")
        for s in suggestions:
            source = "defaults" if s.similar_tasks == 0 else f"{s.similar_tasks} similares"
            print(f"   â€¢ {s.name}: confianza={s.confidence:.3f} (de {source})")
        
        # Simular optimizaciÃ³n y guardar resultado
        # (en realidad optimizarÃ­as con FSBO aquÃ­)
        best_algo = suggestions[0].name
        simulated_score = 0.80 + np.random.uniform(-0.05, 0.15)
        simulated_config = {'dummy': 'config'}
        
        kb.add_entry(meta_features, best_algo, simulated_config, simulated_score)
        
        print(f"   âœ“ Guardado: {best_algo} con score={simulated_score:.3f}")
        
        if i == 1:
            print(f"   ğŸ’­ Primera tarea: usando defaults + heurÃ­sticas")
        elif i == 2:
            print(f"   ğŸ’­ Segunda tarea: ya hay 1 entrada en KB")
        elif i >= 3:
            print(f"   ğŸ’­ Transfer learning activo! {len(kb.entries)} tareas anteriores")
    
    print(f"\n{'â”' * 70}")
    print(f"âœ¨ RESULTADO FINAL:")
    print(f"   â€¢ KB: {len(kb.entries)} entradas")
    print(f"   â€¢ El sistema ahora puede hacer transfer learning efectivo")
    print(f"   â€¢ Cada nueva tarea mejora el sistema ğŸš€")


if __name__ == "__main__":
    demo_sin_kb()
    demo_estrategia_completa()
    demo_mejora_progresiva()
    
    print("\n" + "=" * 70)
    print("âœ… CONCLUSIÃ“N:")
    print("   â€¢ Sistema funciona SIEMPRE (con o sin KB)")
    print("   â€¢ Sin KB: usa heurÃ­sticas inteligentes")
    print("   â€¢ Con KB: usa transfer learning real")
    print("   â€¢ Auto-mejora: cada tarea hace el sistema mÃ¡s inteligente")
    print("=" * 70 + "\n")

