# Reporte: FSBO Transfer Learning para OptimizaciÃ³n de HiperparÃ¡metros

## 1. IntroducciÃ³n

### 1.1 Contexto del Proyecto

Este proyecto implementa la parte de **Transfer Learning** de un sistema de AutoML compuesto por dos mÃ³dulos:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      SISTEMA AUTOML COMPLETO                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   ENTRADA: Nuevo dataset                                            â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚        META-LEARNING              â”‚                            â”‚
â”‚   â”‚   "Â¿QuÃ© algoritmos usar?"         â”‚                            â”‚
â”‚   â”‚                                   â”‚                            â”‚
â”‚   â”‚   Analiza meta-features â†’         â”‚                            â”‚
â”‚   â”‚   Sugiere: [RF, SVM, AdaBoost]    â”‚                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚   â”‚     TRANSFER-LEARNING (FSBO)      â”‚  â† Este mÃ³dulo             â”‚
â”‚   â”‚   "Â¿QuÃ© hiperparÃ¡metros usar?"    â”‚                            â”‚
â”‚   â”‚                                   â”‚                            â”‚
â”‚   â”‚   Optimiza HP para cada algoritmo â”‚                            â”‚
â”‚   â”‚   con pocas evaluaciones          â”‚                            â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   SALIDA: Mejor (algoritmo, configuraciÃ³n) para el dataset         â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 1.2 FSBO (Few-Shot Bayesian Optimization)

FSBO es una tÃ©cnica de meta-learning propuesta por Wistuba & Grabocka (ICLR 2021) que permite encontrar buenas configuraciones de hiperparÃ¡metros con muy pocas evaluaciones mediante:

1. **Deep Kernel GP**: Un Gaussian Process con kernel aprendido por una red neuronal
2. **Meta-Learning**: Pre-entrenar en muchas tareas fuente
3. **Transfer**: Adaptar rÃ¡pidamente a nuevas tareas

---

## 2. ImplementaciÃ³n

### 2.1 Arquitectura del Modelo

```
         x (hiperparÃ¡metros)
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ DeepKernelNetworkâ”‚   Ï†(x): Red neuronal
    â”‚   (2 capas, 128) â”‚   Transforma HP a espacio latente
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
         Ï†(x) âˆˆ â„Â¹Â²â¸
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   RBF Kernel    â”‚   k(Ï†(x), Ï†(x'))
    â”‚   con ARD       â”‚   Similitud en espacio latente
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Gaussian Process â”‚   PredicciÃ³n + incertidumbre
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚
              â–¼
      Î¼(x), ÏƒÂ²(x)
```

### 2.2 Componentes Implementados

| Archivo | DescripciÃ³n | Basado en Paper |
|---------|-------------|-----------------|
| `train_fsbo.py` | Entrenamiento meta-learning | Algoritmo 1 |
| `run_bo.py` | Loop de Bayesian Optimization | Algoritmo 2 |
| `fsbo_optimizer.py` | API observe/suggest | SecciÃ³n 3 |
| `pipeline.py` | IntegraciÃ³n completa | Mejoras propias |

### 2.3 Correspondencia con el Paper

| Paper | CÃ³digo | DescripciÃ³n |
|-------|--------|-------------|
| Ï† (Eq. 3) | `DeepKernelNetwork` | Red 2 capas, 128 unidades |
| k_DK (Eq. 3) | `RBFKernel + ScaleKernel` | Kernel con ARD |
| Task Aug. (Eq. 10-11) | `task_augmentation()` | Invarianza a escala |
| MLL (Eq. 5) | `ExactMarginalLogLikelihood` | FunciÃ³n de pÃ©rdida |
| EI | `expected_improvement()` | Acquisition function |
| Fine-tune (Sec. 3.3) | `finetune_model()` | lr=10â»â´, pocas epochs |
| Warm Start (Sec. 3.4) | `warm_start_model_based()` | InicializaciÃ³n inteligente |

---

## 3. Datos

### 3.1 Estructura de Datos

Los datos estÃ¡n organizados de la siguiente manera:

```
data/
â”œâ”€â”€ configspace/                    # Espacios de bÃºsqueda
â”‚   â”œâ”€â”€ adaboost_configspace.json
â”‚   â”œâ”€â”€ random_forest_configspace.json
â”‚   â”œâ”€â”€ libsvm_svc_configspace.json
â”‚   â””â”€â”€ autosklearn_configspace.json
â”‚
â””â”€â”€ representation_with_scores/     # Datos de entrenamiento
    â”œâ”€â”€ adaboost_target_representation_with_scores.csv
    â”œâ”€â”€ random_forest_target_representation_with_scores.csv
    â”œâ”€â”€ libsvm_svc_target_representation_with_scores.csv
    â””â”€â”€ autosklearn_target_representation_with_scores.csv
```

### 3.2 EstadÃ­sticas de Datos

| Algoritmo | Muestras | Tareas | HP dims | Score medio |
|-----------|----------|--------|---------|-------------|
| AdaBoost | 4,665 | 64 | 8 | 0.744 |
| Random Forest | 10,746 | 64 | 10 | 0.747 |
| LibSVM SVC | 4,523 | 64 | 12 | 0.743 |
| AutoSklearn | 6,481 | 64 | 222 | 0.744 |

### 3.3 GeneraciÃ³n de Datos SintÃ©ticos

Para este proyecto acadÃ©mico, se generaron mÃ©tricas de rendimiento sintÃ©ticas mediante `generate_synthetic_scores.py`:

- Superficie de respuesta con componentes lineales e interacciones
- Diferentes Ã³ptimos por tarea (usando hash del task_id)
- Rango realista [0.50, 0.99]
- Ruido gaussiano Ïƒ=0.03

---

## 4. Modelos Entrenados

### 4.1 Checkpoints

Se entrenaron 4 modelos FSBO con 2000 Ã©pocas cada uno:

| Modelo | Loss Final | Checkpoint |
|--------|------------|------------|
| AdaBoost | -0.0781 | `fsbo_adaboost_20260107_151935.pt` |
| Random Forest | -0.0844 | `fsbo_random_forest_20260107_151938.pt` |
| LibSVM SVC | -0.0858 | `fsbo_libsvm_svc_20260107_151942.pt` |
| AutoSklearn | -0.0851 | `fsbo_autosklearn_20260107_151946.pt` |

### 4.2 HiperparÃ¡metros de Entrenamiento

```python
epochs = 2000
batch_size = 50
learning_rate = 1e-3
hidden_dim = 128
task_augmentation = True
```

---

## 5. Pipeline de IntegraciÃ³n

### 5.1 Flujo Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     PIPELINE COMPLETO                               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                     â”‚
â”‚   ENTRADA: Dataset + Algoritmos sugeridos por Meta-Learning         â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  1. EXTRACCIÃ“N DE META-FEATURES                             â”‚   â”‚
â”‚   â”‚     - n_samples, n_features, n_classes                      â”‚   â”‚
â”‚   â”‚     - class_imbalance, ratios                               â”‚   â”‚
â”‚   â”‚     â†’ Usado para warm start inteligente                     â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  2. ASIGNACIÃ“N DINÃMICA DE PRESUPUESTO                      â”‚   â”‚
â”‚   â”‚     - MÃ¡s budget a algoritmos con mayor confianza           â”‚   â”‚
â”‚   â”‚     - MÃ¡s budget a espacios mÃ¡s complejos                   â”‚   â”‚
â”‚   â”‚     â†’ Optimiza uso de evaluaciones                          â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚  3. PARA CADA ALGORITMO:                                    â”‚   â”‚
â”‚   â”‚                                                             â”‚   â”‚
â”‚   â”‚     a) Warm Start Inteligente                               â”‚   â”‚
â”‚   â”‚        - Buscar configs de tareas similares (KB)            â”‚   â”‚
â”‚   â”‚        - Usar modelo pre-entrenado                          â”‚   â”‚
â”‚   â”‚                                                             â”‚   â”‚
â”‚   â”‚     b) Transfer de HiperparÃ¡metros                          â”‚   â”‚
â”‚   â”‚        - Ponderar configs por similitud                     â”‚   â”‚
â”‚   â”‚        - Interpolar configuraciones                         â”‚   â”‚
â”‚   â”‚                                                             â”‚   â”‚
â”‚   â”‚     c) BO Loop                                              â”‚   â”‚
â”‚   â”‚        - Expected Improvement                               â”‚   â”‚
â”‚   â”‚        - Fine-tuning periÃ³dico                              â”‚   â”‚
â”‚   â”‚        - Early stopping si converge                         â”‚   â”‚
â”‚   â”‚                                                             â”‚   â”‚
â”‚   â”‚     d) Guardar en Knowledge Base                            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                â”‚                                                    â”‚
â”‚                â–¼                                                    â”‚
â”‚   SALIDA: Mejor (algoritmo, configuraciÃ³n, score)                   â”‚
â”‚                                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 Mejoras Implementadas

#### Mejora 1: Warm Start Inteligente con Meta-Features

```python
class IntelligentWarmStart:
    """
    Usa meta-features del dataset para encontrar tareas similares
    y transferir sus mejores configuraciones.
    """
    def get_initial_configs(self, dataset_meta, algorithm, optimizer, n_init):
        # 1. Buscar en base de conocimiento
        similar_configs = self.kb.find_similar_configs(dataset_meta, algorithm)
        
        # 2. AÃ±adir configs transferidas (con perturbaciÃ³n)
        configs = [self._perturb_config(c) for c in similar_configs]
        
        # 3. Completar con sugerencias del modelo
        configs.extend(optimizer.suggest_initial(remaining))
        
        return configs
```

#### Mejora 2: Ajuste DinÃ¡mico de Presupuesto

```python
class DynamicBudgetAllocator:
    """
    Asigna mÃ¡s evaluaciones a:
    - Algoritmos con mayor confianza del meta-learner
    - Espacios de hiperparÃ¡metros mÃ¡s complejos
    """
    def allocate(self, suggestions):
        # Score = 0.6 * confianza + 0.4 * complejidad
        # Budget proporcional al score
```

#### Mejora 3: Transfer de HiperparÃ¡metros

```python
class HyperparameterTransfer:
    """
    Transfiere conocimiento de optimizaciones anteriores.
    """
    def get_transfer_prior(self, dataset_meta, algorithm):
        # 1. Buscar tareas similares
        # 2. Ponderar por similitud y score histÃ³rico
        # 3. Retornar prior ponderado
```

### 5.3 Base de Conocimiento

El sistema mantiene una base de conocimiento que almacena:
- Meta-features de datasets procesados
- Mejores configuraciones encontradas
- Scores obtenidos

Esto permite mejorar continuamente el warm start para nuevas tareas.

---

## 6. API de Uso

### 6.1 FSBOOptimizer (observe/suggest)

```python
from fsbo_optimizer import FSBOOptimizer

# Cargar modelo pre-entrenado
optimizer = FSBOOptimizer.from_pretrained('random_forest')

# Warm start
initial_configs = optimizer.suggest_initial(n=5)
for config in initial_configs:
    score = train_and_evaluate(config)
    optimizer.observe(config, score)

# BO loop
for _ in range(budget):
    config = optimizer.suggest()
    score = train_and_evaluate(config)
    optimizer.observe(config, score)

# Resultado
best_config, best_score = optimizer.get_best()
```

### 6.2 Pipeline Completo

```python
from pipeline import run_pipeline, AlgorithmSuggestion

# Sugerencias del meta-learning
suggestions = [
    AlgorithmSuggestion('random_forest', confidence=0.85),
    AlgorithmSuggestion('adaboost', confidence=0.70),
]

# FunciÃ³n de evaluaciÃ³n
def evaluate(algorithm, config, X_tr, y_tr, X_val, y_val):
    model = get_model(algorithm, **config)
    model.fit(X_tr, y_tr)
    return model.score(X_val, y_val)

# Ejecutar pipeline
result = run_pipeline(
    X_train, y_train, X_val, y_val,
    suggested_algorithms=suggestions,
    evaluation_fn=evaluate,
    total_budget=100
)

print(f"Mejor: {result.best_algorithm} con {result.best_score:.4f}")
```

---

## 7. Resultados Experimentales

### 7.1 Test del Pipeline

```
ğŸ“Š Dataset: test_synthetic (400 samples, 20 features, 3 classes)

ğŸ’° Presupuesto asignado:
   - adaboost: 20 evaluaciones (confianza=0.85)
   - random_forest: 19 evaluaciones (confianza=0.75)

ğŸ† Resultados:
   1. random_forest: 0.8054 (19 evals)
   2. adaboost: 0.7965 (16 evals, early stop)

â±ï¸ Tiempo total: 1.1 segundos
ğŸ“ˆ Evaluaciones totales: 35
```

### 7.2 Observaciones

- **Early stopping** funcionÃ³: AdaBoost parÃ³ en 16 de 20 evaluaciones
- **Warm start** efectivo: Scores iniciales ya en rango 0.72-0.78
- **Transfer** beneficioso: Configuraciones similares ayudaron

---

## 8. Estructura del Proyecto

```
transfer-learning/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ configspace/              # Espacios de bÃºsqueda (4 JSON)
â”‚   â””â”€â”€ representation_with_scores/  # Datos con scores (4 CSV)
â”œâ”€â”€ doc/
â”‚   â”œâ”€â”€ 2101.07667v1.pdf          # Paper FSBO
â”‚   â””â”€â”€ report.md                 # Este documento
â”œâ”€â”€ experiments/
â”‚   â”œâ”€â”€ checkpoints/              # Modelos entrenados (4 .pt)
â”‚   â”œâ”€â”€ results/                  # Resultados de experimentos
â”‚   â””â”€â”€ knowledge_base.json       # Base de conocimiento
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ generate_synthetic_scores.py  # Generador de datos
â”‚   â”œâ”€â”€ train_fsbo.py             # Entrenamiento
â”‚   â”œâ”€â”€ run_bo.py                 # BO loop
â”‚   â”œâ”€â”€ fsbo_optimizer.py         # API observe/suggest
â”‚   â””â”€â”€ pipeline.py               # IntegraciÃ³n completa
â””â”€â”€ requirements.txt
```

---

## 9. Referencias

- Wistuba, M., & Grabocka, J. (2021). *Few-Shot Bayesian Optimization with Deep Kernel Surrogates*. ICLR 2021.
- Wilson, A. G., et al. (2016). *Deep Kernel Learning*. AISTATS 2016.
- Snoek, J., et al. (2012). *Practical Bayesian Optimization of Machine Learning Algorithms*. NeurIPS 2012.
